<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion Models">
  <!-- <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/> -->
  <!-- <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/> -->
  <!-- <meta property="og:url" content="URL OF THE WEBSITE"/> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
  <!-- <meta property="og:image:width" content="1200"/> -->
  <!-- <meta property="og:image:height" content="630"/> -->


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG"> -->
  <!-- <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="T2I Generation, Diffusion, Multimodal">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">DiffBlender: Scalable and Composable</h1>
            <h1 class="title is-2 publication-title">Multimodal Text-to-Image Diffusion Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                  <a href="https://bit.ly/sungnyunkim" style="color:#f68946;font-weight:normal;">Sungnyun Kim</a><sup>*<span>&#8224;</span></sup>,</span>
                <span class="author-block">
                  <a href="https://ssuhan.github.io" style="color:#F2A900;font-weight:normal;">Junsoo Lee</a><sup><span>&#8224;</span></sup>,</span>
                  <span class="author-block">
                      <a href="https://github.com/Kibeom-Hong" style="color:#008AD7;font-weight:normal;">Kibeom Hong</a><sup>*</sup>,</span>
                    <span class="author-block">
                      <a href="https://scholar.google.com/citations?user=YUcWWbEAAAAJ&hl=en" style="color:#F2A900;font-weight:normal;">Daesik Kim</a>,</span>
                    <span class="author-block">
                      <a href="https://nmhkahn.github.io" style="color:#F2A900;font-weight:normal;">Namhyuk Ahn</a><sup><span>&#8225;</span></sup>
                    </span>

                  </div>

                  <br>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> KAIST AI; </span>
                    <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b> NAVER WEBTOON AI; </span>
                    <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> Yonsei University; </span>
                  <br>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Work done while interning at NAVER WEBTOON AI</small></span>
                    <span class="eql-cntrb"><small><br><sup><span>&#8224;</span></sup>Equal contribution</small></span>
                    <span class="eql-cntrb"><small><br><sup><span>&#8225;</span></sup>Corresponding author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2305.15194.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block"> -->
                    <!--   <a href="static/pdfs/supplementary_material.pdf" target="_blank" -->
                    <!--   class="external-link button is-normal is-rounded is-dark"> -->
                    <!--   <span class="icon"> -->
                    <!--     <i class="fas fa-file-pdf"></i> -->
                    <!--   </span> -->
                    <!--   <span>Supplementary</span> -->
                    <!-- </a> -->
                  <!-- </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/sungnyun/diffblender" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2305.15194" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser"> -->
<!--   <div class="container is-max-desktop"> -->
<!--     <div class="hero-body"> -->
<!--       <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
<!--         <!-1- Your video here -1-> -->
<!--         <source src="static/videos/banner_video.mp4" -->
<!--         type="video/mp4"> -->
<!--       </video> -->
<!--       <h2 class="subtitle has-text-centered"> -->
<!--         Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. --> 
<!--       </h2> -->
<!--     </div> -->
<!--   </div> -->
<!-- </section> -->
<!-- End teaser video -->


<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" width="150%" src="assets/fig1.png">
      <h2 class="subtitle has-text-justified">
          <p style="font-family:Times New Roman"><b>Figure 1. Generated results with multimodal conditions. 
          By incorporating various input modalities, DiffBlender successfully synthesizes high-fidelity and diverse samples.</b></p>
      </h2>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The recent progress in <a href="https://github.com/CompVis/stable-diffusion">diffusion-based text-to-image generation models</a> has
            significantly expanded generative capabilities via conditioning the text descriptions.
            However, since relying solely on text prompts is still restrictive for fine-grained
            customization, we aim to extend the boundaries of conditional generation to
            incorporate diverse types of modalities, <i>e.g.</i>, sketch, box, and style embedding, 
            simultaneously. We thus design a multimodal text-to-image diffusion model, coined as
            <b>DiffBlender</b>, that achieves the aforementioned goal in a single model by training
            only a few small <a href="https://github.com/lllyasviel/ControlNet">hypernetworks</a>. <b>DiffBlender facilitates a convenient scaling of
            input modalities, without altering the parameters of an existing large-scale
            generative model to retain its well-established knowledge.</b> Furthermore, our study sets
            new standards for multimodal generation by conducting quantitative and qualitative
            comparisons with existing approaches. By diversifying the channels of conditioning
            modalities, DiffBlender faithfully reflects the provided information or, in its absence, 
            creates imaginative generation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"> Model Architecture </h2> 
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <div class="content has-text-justified">
          <ul>
            <li>We design DiffBlender to facilitate the convenient addition of different modalities by categorizing them into three types: image-form, spatial tokens, and non-spatial tokens.</li>
            <li>It is intuitively extended to additional modalities while achieving a low training cost through a partial update of hypernetworks.</li>
          </ul>
        </div>        
        <img id="model" width="100%" src="assets/fig3.png">
        <h3 class="subtitle has-text-centered">
          <p style="font-family:Times New Roman"><b>Figure 2. Overview of DiffBlender architecture. 
              (a) illustrates the four types of conditions employed in DiffBlender and indicates where each part of information is used in the UNet layers. 
              (b) focuses on the purple region in (a) to provide details of the DiffBlender's conditioning process. 
              The lock-marked layers represent being fixed as the original parameters of SD. i
              The remaining modules, small hypernetworks, denote the learnable parameters of DiffBlender.</b></p>
        </h3>   

    </div>
  </div>
</section>


<!-- Image carousel -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-five-fifths">
          <h2 class="title is-3"> Multimodal Text-to-Image Generation </h2>
          </div>
        </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-4"><font color="#545454">Versatile applications of DiffBlender</font></h2>
          <img id="result" width="100%" src="assets/fig2.png">
          <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
             DiffBlender enables flexible manipulation of conditions, providing the customized generation aligned with user preferences. 
             Note that all results are generated by our single model at once, not in sequence.
            </p>
          </h2>                 
        </div>
      </div>


    <h2 class="title is-4"><font color="#545454">Reference-guided and semantic-preserved generation</font></h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="assets/fig6.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            When a source image is provided, DiffBlender demonstrates the results preserving the structure inherent in that image, while effectively incorporating the style elements from a reference image.
            </p>
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig11-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            When a source image is provided, DiffBlender demonstrates the results preserving the structure inherent in that image, while effectively incorporating the style elements from a reference image.
            </p>
        </h2>      
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig11-2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            When a source image is provided, DiffBlender demonstrates the results preserving the structure inherent in that image, while effectively incorporating the style elements from a reference image.
            </p>
        </h2>      
     </div>
  </div>


    <h2 class="title is-4"><font color="#545454">Object reconfiguration</font></h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="assets/fig7.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            DiffBlender has the capability to flexibly reconstruct a new scene by utilizing partial information from an input image. 
            This enables us to customize scenes while retaining the contextual cues and layout from the original image.
            </p>
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig16.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Object reconfiguration for clothes. 
            By altering the reference images associated with the clothing, it can reconfigure the scenes, modifying the outfit and style of the violinist.
            </p>
        </h2>      
      </div>
  </div>


    <h2 class="title is-4"><font color="#545454">Mode-specific guidance</font></h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="assets/fig9.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Each row depicts the results of style and sketch guidance, respectively. 
            We linearly manipulate the mode-specific guidance scale, where the center indicates scale=0 (original guidance).
            </p>
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig13-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Sketch guidances.
            </p>
        </h2>      
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig13-2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Depth guidances.
            </p>
        </h2>      
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig13-3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Color and style guidances.
            </p>
        </h2>      
      </div>
  </div>


    <h2 class="title is-4"><font color="#545454">Interpolating non-spatial conditions.</font></h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="assets/fig10.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Interpolating latents for the color palettes and reference image embeddings.
            </p>
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig14-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Interpolating latents for the color palettes.
            </p>
        </h2>      
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig14-2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Interpolating latents for the color palettes.
            </p>
        </h2>      
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig15-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Interpolating latents for the reference image embeddings.
            </p>
        </h2>      
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig15-2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            Interpolating latents for the reference image embeddings.
            </p>
        </h2>      
      </div>
  </div>

    <h2 class="title is-4"><font color="#545454">Manipulating spatial conditions</font></h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="assets/fig12-1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            The box grounded with sun is shifted from the upper left to the upper right in a counter-clockwise direction. 
            Throughout this shift, the partial sketch and reference image are consistently reflected, although there are slight variations in the terrain, brightness, or contrast, depending on the sun's position.
            </p>
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="assets/fig12-2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
            <p style="font-family:Times New Roman">
            The astronaut's arms are gradually elevated, with the sketch and style being maintained.
            </p>
        </h2>      
      </div>
  </div>


</div>
</div>
</section>
<!-- End image carousel -->



<section class="hero is-small" style="backgroud-color:#fff9e6">
  <div class="columns is-centered has-text-centered">
      <div style="width:90%;">

        <!-- Abstract. -->
        <div style="float:left; width:47.1%; border: 0px solid black;">
          <h2 class="title is-5">Functional difference over previous works</h2>
          <div class="content has-text-justified">
           Table below summarizes the comparisons with previous multimodal T2I diffusion models. 
           The existing studies have limitations; supporting only a single modality at a time; 
           supporting only similar types of modalities; 
           supporting multiple modalities but being sensitive to hyperparameters when used together; 
           or training models from scratch with a massive number of parameters without leveraging the existing knowledge.
           We highlight that DiffBlender supports diverse input modalities, updates only partial parameters, and renders multimodal training, as well as extends to future conditioning modalities.
          </div>  

          <div class="column is-five-fifths">
              <div class="columns is-centered">
                <img id="result" width="105%" src="assets/table1.png">
                
              </div>
          </div>
        </div>
        <!--/ Abstract. -->

        <div style="float:right; width:47.8%; border: 0px solid black;">
          <h2 class="title is-5">Evaluation with baselines</h2>
          <div class="content has-text-justified">
            We set new standards for multimodal generation by conducting quantitative (Table) and qualitative (Figure) comparisons with existing approaches.
          </div>  

          <div class="column is-five-fifths">
              <div class="columns is-centered">
                <img id="modulated_training" width="97%" src="assets/table2.png">
                
              </div>
          </div>
        </div>

      </div>  
    </div>     
</section>



<!-- Youtube video -->
<!-- <section class="hero is-small is-light"> -->
<!--   <div class="hero-body"> -->
<!--     <div class="container"> -->
<!--       <!-1- Paper video. -1-> -->
<!--       <h2 class="title is-3">Video Presentation</h2> -->
<!--       <div class="columns is-centered has-text-centered"> -->
<!--         <div class="column is-four-fifths"> -->
          
<!--           <div class="publication-video"> -->
<!--             <!-1- Youtube embed code here -1-> -->
<!--             <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
<!--           </div> -->
<!--         </div> -->
<!--       </div> -->
<!--     </div> -->
<!--   </div> -->
<!-- </section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small"> -->
<!--   <div class="hero-body"> -->
<!--     <div class="container"> -->
<!--       <h2 class="title is-3">Another Carousel</h2> -->
<!--       <div id="results-carousel" class="carousel results-carousel"> -->
<!--         <div class="item item-video1"> -->
<!--           <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
<!--             <!-1- Your video file here -1-> -->
<!--             <source src="static/videos/carousel1.mp4" -->
<!--             type="video/mp4"> -->
<!--           </video> -->
<!--         </div> -->
<!--         <div class="item item-video2"> -->
<!--           <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
<!--             <!-1- Your video file here -1-> -->
<!--             <source src="static/videos/carousel2.mp4" -->
<!--             type="video/mp4"> -->
<!--           </video> -->
<!--         </div> -->
<!--         <div class="item item-video3"> -->
<!--           <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
<!--             <!-1- Your video file here -1-> -->
<!--             <source src="static/videos/carousel3.mp4" -->
<!--             type="video/mp4"> -->
<!--           </video> -->
<!--         </div> -->
<!--       </div> -->
<!--     </div> -->
<!--   </div> -->
<!-- </section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light"> -->
<!--   <div class="hero-body"> -->
<!--     <div class="container"> -->
<!--       <h2 class="title">Poster</h2> -->

<!--       <iframe  src="static/pdfs/sample.pdf" width="100%" height="550"> -->
<!--           </iframe> -->
        
<!--       </div> -->
<!--     </div> -->
<!--   </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@article{kim2023diffblender,
    title={DiffBlender: Scalable and Composable Multimodal Text-to-Image Diffusion Models},
    author={Kim, Sungnyun and Lee, Junsoo and Hong, Kibeom and Kim, Daesik and Ahn, Namhyuk},
    journal={arXiv preprint arXiv:2305.15194},
    year={2023}
}
  </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
          This page is adapted from 
          <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>,
          <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>,
          <a href="https://x-decoder-vl.github.io">X-Decoder</a>, 
          and <a href="https://gligen.github.io">GLIGEN</a>,
          licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
